## Early History
1. **Greek mythology, Golems**: These are early examples of artificial beings in folklore and mythology. In Greek mythology, there were stories of mechanical beings like Talos, a giant bronze automaton made by Hephaestus. In Jewish folklore, a Golem is a creature formed out of clay and brought to life by a rabbi. These stories are among the first to conceptualize the idea of artificial life or intelligence.
    
2. **First attempt: Ramon Lull, 13th century**: Ramon Lull was a philosopher who attempted to create a "universal logic machine" that could answer any question. This can be seen as an early conceptual prototype of AI, even though the technology to build such a machine didn't exist in his time.
    
3. **Davinci's walking animals**: Leonardo da Vinci, the renowned Italian artist and inventor, sketched designs for a number of machines, some of which resembled animals and were designed to move like them. This can be seen as an early form of robotics, a field closely related to AI.
    
4. **Descartes**: These philosophers had ideas relevant to AI. Descartes is known for his mind-body dualism, which separates the physical body from the mind or soul, which could be seen as a precursor to the concept of software (mind) and hardware (body) in AI. 
5. **Gottfried Leibniz**: Leibniz developed a type of mechanical calculator, and he envisioned a universal language of symbols and a calculus of reasoning, which are central to the development of programming languages and logical reasoning in AI.

> [!Note] A bit of computer history rather
## Statistics and Mathematical Decision Making
6. **1700s-1800s: Statistics & Mathematical decision making**: This era saw the development of mathematical and logical tools that are now fundamental in AI. Statistics and decision-making models are central to AI's ability to predict, decide, and learn from data.
    
    - **Thomas Bayes: reasoning about the probability of events**: Bayes was an English statistician and theologian known for Bayes' theorem, a fundamental principle in probability theory and statistics. Bayesian inference is a method of statistical inference that is central to many algorithms in AI and machine learning.
        
    - **George Boole: logical reasoning / binary algebra**: Boole developed Boolean algebra, a branch of algebra in which the values of the variables are the truth values true and false. This has been fundamental in the development of digital electronic hardware and is the basis of all modern computer arithmetic.
        
    - **Gottlob Frege: Predicate logic**: Frege was a German philosopher and logician who made significant contributions to the development of modern symbolic logic, also known as mathematical logic. In predicate logic, sentences are analyzed into two parts: the subject and the predicate.
	    - Universal quantifier (∀), often read as "for all" or "given any". For example, "For all x, if x is a human, then x is mortal."
	    - Existential quantifier (∃), often read as "there exists" or "for some". For example, "There exists an x such that x is a human and x is immortal."

## Early Machines
- 6. **1832: Charles Babbage & Ada Byron / Lovelace: designed Analytical Engine (1832), programmable mechanical calculating machines**: Charles Babbage, a British mathematician, designed the Analytical Engine, a general-purpose mechanical computer that was never built, but has been recognized as a conceptually modern computer. Ada Lovelace, often credited as the world's first programmer, recognized the full potential of Babbage's engine and wrote what are considered the first algorithms intended to be processed by a machine.
    
7. **1936: Universal Turing Machine**: Alan Turing, a British mathematician and logician, conceptualized the Universal Turing Machine, which is a theoretical device that manipulates symbols on a strip of tape according to a table of rules. This concept played a pivotal role in the development of the digital computer.
    
    - **Computing Machinery and Intelligence - explored AI!**: This is one of Alan Turing's most famous papers, published in 1950, in which he proposed the idea of the Turing Test to measure a machine's ability to exhibit intelligent behavior equivalent to, or indistinguishable from, that of a human. The Turing Test has been highly influential in AI.

1. **1946: John von Neumann Universal Computing Machine**: John von Neumann, a Hungarian-American mathematician and physicist, helped develop the architecture of the modern digital computer, often referred to as the Von Neumann architecture. This was a key step in the evolution of computers, allowing them to be programmed and paving the way for the development of AI.
    
9. **1943: Warren McCulloch & Walter Pitts: cogsci representation of neuron; Frank Rosenblatt uses to create Perceptron (-> neural networks by way of MLP)**: Warren McCulloch and Walter Pitts, two American neurophysiologists and cyberneticians, published a paper on how neurons might work and proposed a simple model for neural networks. 
10. **1958, Frank Rosenblatt** expanded on their work and invented the perceptron, an algorithm for supervised learning of binary classifiers. The perceptron is a type of artificial neuron and forms the basis for multi-layer perceptrons (MLPs), which are foundational to many modern neural network models used in AI.

## The birth of AI or the Golden Era

- AI, as a term, was coined at the Dartmouth workshop in 1956. The objective was to simulate all aspects of human intelligence. Key figures include John McCarthy (one of the "fathers" of AI and the one who coined the term "Artificial Intelligence"), Marvin Minsky, Arthur Samuel, Oliver Selfridge, Ray Solomonoff, Allen Newell, and Herbert Simon.

- Newell and Simon developed heuristics that led to logic theories and created the General Problem Solver, a program that attempted to model human problem-solving capabilities. The GPS also introduced the use of heuristics, which are rules of thumb or strategies used to make the problem-solving process more efficient.

- Selfridge contributed to the field of computer vision, which is about enabling computers to "see" and interpret visual data.

- Natural Language Processing (NLP) emerged as a field dedicated to enabling computers to understand and respond to human language.

- Stanford Research Institute developed Shakey, one of the first robots that could perceive and interact with its environment.

- Feigenbaum helped create Expert systems, computer systems that emulate the decision-making ability of a human expert.

- Good Old-Fashioned Artificial Intelligence (GOFAI) or symbolism, relied on symbolic systems for knowledge representation. It includes logic-based and knowledge-based (expert) systems.
 
In 1955, M.L. Minsky wrote:
	A “**machine may be ‘trained’** by a ‘trial and error’ process to acquire one of a range of input-output functions. Such a machine, when placed in an appropriate environment and given a criterior of ‘success’ or ‘failure’ can be trained to exhibit ‘goal-seeking’ behavior.”

## The AI Winter ~70s
- The Lighthill report, prepared by James Lighthill, criticized the lack of fulfilled promises in AI. This report led to reduced funding and interest in AI research, causing what's known as the AI Winter.

## AI's comeback
- Geoffrey Hinton optimized backpropagation in 2006, a key technique for training neural networks, leading to advancements in "connectionism" or neural network models.
- The year 2015 was significant for AI in industry, with many companies starting to implement AI and machine learning technologies in their operations.
- AlphaGo is a computer program developed by Google DeepMind that plays the board game Go. In 2016, AlphaGo famously defeated the world champion Go player, a feat considered a significant milestone in AI due to the game's complexity.


# What is AI?
AI means the theory and development of computer systems able to perform tasks that normally require human intelligence, **such as visual perception, speech recognition, decision-making and translation between languages.**
- Simulate any intellectual task
> [!note] A way to think of AI is: The Industrial revolution was created by people trying to automate the body. AI is the attempt to automate the Brain.


# Introduction to AI
## Definition of Artificial Intelligence
AI means the theory and development of computer systems able to perform tasks that normally require human intelligence, **such as visual perception, speech recognition, decision-making and translation between languages.**
- Simulate any intellectual task
> [!note] A way to think of AI is: The Industrial revolution was created by people trying to automate the body. AI is the attempt to automate the Brain.


# Key components of AI
>[!Note] Also could be called Sub Fields. From Wikipedia: These are reasoning and problem solving, knowledge, representation, planning, learning, natural language, processing, perception, motion, and manipulation, social intelligence, and general intelligence.

1.  Representation: Representation deals with how knowledge is stored and structured within an AI system. This includes the choice of data structures, ontologies, and models that allow the system to understand and reason about the problem domain. Different AI systems may use different representations depending on the nature of the task and the type of data involved.
> [!example]  In an AI system designed to assess students' reading comprehension, the knowledge representation might involve encoding text passages and corresponding questions in a structured format that allows the system to understand and reason about the content. This could include representing the text as a graph, where nodes represent concepts, and edges represent relationships between those concepts.
> Example 2: In a language translation AI system, the knowledge representation might involve using word embeddings (numeric representations of words) that capture semantic and syntactic relationships between words.

2.  Reasoning: Reasoning is the process by which an AI system draws conclusions, makes decisions, or solves problems based on the knowledge represented within the system. Reasoning can be deductive (applying general rules to specific situations), inductive (inferring general rules from specific examples), or abductive (finding the most likely explanation for a set of observations).
> [!example]  An AI system that helps students improve their essay writing might use reasoning to evaluate the structure, coherence, and argumentation of a student's essay based on a set of predefined rules or criteria. For example, the system might use deductive reasoning to identify gaps in the essay's argument or inductive reasoning to suggest improvements based on patterns observed in high-quality essays.
> Example 2: A diagnostic AI system for medical purposes might use deductive reasoning to identify a patient's illness based on a set of symptoms and known medical rules, or inductive reasoning to learn new relationships between symptoms and illnesses from a database of patient records.

3.  Learning: Learning is the process by which an AI system acquires new knowledge or improves its performance based on exposure to data. In machine learning, this often involves training algorithms on large datasets to build models that can make predictions or classify new data points. Learning can be supervised (using labeled training data), unsupervised (without labeled data), or reinforcement learning (learning from interactions with an environment).
> [!example] In an AI system designed to teach English pronunciation, the learning component could involve training a machine learning model on a dataset of audio recordings of native speakers and non-native speakers. The model would learn to recognize and correct common pronunciation errors by identifying patterns in the acoustic features of the speech data.
> Example 2: A chatbot AI designed to help students practice their English might learn from a dataset of conversations, improving its ability to understand and generate appropriate responses over time.

4.  Communication: Communication refers to the interaction between an AI system and its users or other systems. This can involve natural language processing (NLP) for understanding and generating human language, as well as other forms of input and output like speech recognition, text-to-speech synthesis, or visual displays.
> [!example] An AI-powered chatbot for English language practice might use natural language processing (NLP) to understand students' text or speech inputs and generate appropriate responses in English. This would involve processing the input language, determining the intent of the message, and formulating a coherent response that helps the student practice their language skills.
> Example 2: An AI-powered virtual teaching assistant in an English school might use NLP to understand students' questions and provide accurate and helpful answers in a natural, human-like manner.


##  Traditional AI vs. Machine Learning vs. Deep Learning
1.  Traditional AI: Traditional AI, also known as rule-based AI or symbolic AI, relies on explicitly programmed rules and logic to perform tasks that require human intelligence. These systems use a knowledge base, where facts and rules are stored, and an inference engine, which applies logical reasoning to draw conclusions based on the given knowledge. Traditional AI often involves expert systems, knowledge representation, and rule-based systems.
> [!example] A simple expert system for grammar checking could use a set of pre-defined rules to identify and correct common grammar errors in a text.

2.  Machine Learning (ML): ML is a subset of AI that focuses on developing algorithms that allow computers to learn and improve from data without explicit programming. Instead of using handcrafted rules, ML algorithms use statistical methods to analyze input data and generate models that can make predictions or decisions based on new data.
> [!example] An ML algorithm could be trained on a large dataset of student essays to automatically identify and correct grammar mistakes based on patterns learned from the data.

3.  Deep Learning: Deep learning is a subset of machine learning that uses artificial neural networks to model complex patterns and representations in data. These neural networks consist of multiple layers of interconnected nodes, allowing them to learn hierarchical representations of the input data. Deep learning has been particularly successful in tasks such as image and speech recognition, natural language processing, and game playing.
> [!example] A deep learning model could be trained to automatically grade student essays, not only based on grammar but also considering aspects like coherence, style, and content.

# Comparing Traditional AI, Machine Learning, and Deep Learning
-   Traditional AI relies on handcrafted rules and logic, while Machine Learning and Deep Learning learn patterns from data.
-   Machine Learning and Deep Learning are both subsets of AI, with Deep Learning being a specific approach within Machine Learning that uses artificial neural networks.
-   Traditional AI is generally more interpretable and easier to understand since it is based on explicitly programmed rules. However, it can be limited in its ability to handle complex tasks and may require significant manual effort to create and maintain the rules.
-   Machine Learning and Deep Learning can handle more complex tasks and generalize better to new data, but their models can be more difficult to interpret and understand due to their data-driven nature.
-   Deep Learning models can automatically learn hierarchical representations of the data, making them particularly effective for tasks with large amounts of data or complex patterns. However, they may require more computational resources and data compared to other Machine Learning methods.
> [!summary] In summary, the main difference between Traditional AI, Machine Learning, and Deep Learning lies in their approaches to solving problems. Traditional AI uses pre-defined rules, while Machine Learning and Deep Learning learn from data, with Deep Learning employing artificial neural networks for more complex tasks.
